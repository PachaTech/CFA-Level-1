{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129e57f3",
   "metadata": {},
   "source": [
    "# Module 10.1: Linear Regression Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7fb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.core.common import random_state\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7ab11",
   "metadata": {},
   "source": [
    "### LOS 10.a: Describe a simple linear regression model, how the least squares criterion is used to estimate regression coefficients, and the interpretation of these coefficients.\n",
    "\n",
    "The purpose of simple linear regression is to explain the variation in a dependent variable in terms of the variation in a single independent variable. Here, the term variation is interpreted as the degree to which a variable differs from its mean value. Don't confuse variation with variance—they are related, but they are not the same.\n",
    "\n",
    "\n",
    "$\\text{variation in Y} = {\\Large\\sum_{1}^{n}} (Y_i - \\bar{Y})^2$\n",
    "\n",
    "* The **dependent variable** is the variable whose variation is explained by the independent variable. We are interested in answering the question, \"What explains fluctuations in the dependent variable?\" The dependent variable is also referred to as the terms explained variable, endogenous variable, or predicted variable.\n",
    "</br>\n",
    "\n",
    "* The **independent variable** is the variable used to explain the variation of the dependent variable. The independent variable is also referred to as the terms explanatory variable, exogenous variable, or predicting variable.\n",
    "</br>\n",
    "\n",
    "**Example: Dependent vs. independent variables**\n",
    "\n",
    "Suppose you want to predict stock returns with GDP growth. Which variable is the independent variable?\n",
    "\n",
    "&emsp;**Answer:**\n",
    "\n",
    "Because GDP is going to be used as a predictor of stock returns, stock returns are being *explained* by GDP. Hence, stock returns are the dependent (explained) variable, and GDP is the independent (explanatory) variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b41f00",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression Model\n",
    "\n",
    "The following linear regression model is used to describe the relationship between two variables, $X$ and $Y$:\n",
    "<br></br>\n",
    "$\\Large{Y_i = b_0 + b_1X_i + \\epsilon_i ,... i = 1, ..., n}$\n",
    "\n",
    "&emsp; \n",
    "\n",
    "<U>where:</U>\n",
    "\n",
    "$Y_i$ = ith observation of the dependent variable, $Y$ \n",
    "\n",
    "$X_i$ = ith observation of the independent variable, $X$\n",
    " \n",
    "$b_0$ = regression intercept term\n",
    " \n",
    "$b_1$ = regression slope coefficient\n",
    " \n",
    "$\\epsilon_i$ = **residual** for the $i_{th}$ observation (also referred to as the disturbance term or error term);\n",
    "\n",
    "Based on this regression model, the regression process estimates an equation for a line through a scatter plot of the data that \"best\" explains the observed values for $Y$ in terms of the observed values for $X$.\n",
    "\n",
    "\n",
    "#### Simple Linear Regression Model\n",
    "\n",
    "The linear equation, often called the line of best fit or regression line, takes the following form:\n",
    "<br></br>\n",
    "\n",
    "$\\Large\\hat{Y}_{i} = \\hat{b}_{0} + \\hat{b}_{1}X_i i=1,2,3...,n$\n",
    "\n",
    "&emsp; \n",
    "\n",
    "<U>where:</U>\n",
    "\n",
    "$\\hat{Y}_{i}$ = estimated value of $Y_i$ given $X_i$\n",
    "\n",
    "$\\hat{b}_{0}$ = estimated intercept term.\n",
    "\n",
    "$\\hat{b}_{1}$ = estimated slope coefficient.\n",
    "\n",
    " \n",
    "<br>\n",
    "The hat \"^\" above a variable or parameter indicates a predicted value.\n",
    "</br>\n",
    "\n",
    "\n",
    "Thus, the regression line is the line that minimizes the **SSE**. This explains why simple linear regression is frequently referred to as ordinary least squares **(OLS) regression**, and the values determined by the estimated regression equation, $\\hat{Y}_i$, are called least squares estimates.\n",
    "\n",
    "<br>\n",
    "The estimated slope coefficient $\\hat{b}_{1}$ for the regression line describes the change in $Y$ for a one-unit change in $X$. It can be positive, negative, or zero, depending on the relationship between the regression variables. The slope term is calculated as follows:\n",
    "</br>\n",
    "&emsp; \n",
    "\n",
    "$\\Large\\hat{b}_{1} = \\frac{CovXY}{\\sigma^2_X}$\n",
    "\n",
    "The intercept term $\\hat{b}_{0}$ is the line's intersection with the $Y$-axis at $X = 0$. It can be positive, negative, or zero. A property of the least squares method is that the intercept term may be expressed as follows:\n",
    "\n",
    "&emsp; \n",
    "$\\large\\hat{b}_{0}=\\bar{Y}−\\hat{b}_{1}\\bar{X}$\n",
    "\n",
    "where:\n",
    "\n",
    "Y = mean of Y\n",
    "\n",
    "X = mean of X\n",
    "\n",
    "The intercept equation highlights the fact that the regression line passes through a point with coordinates equal to the mean of the independent and dependent variables (i.e., the point X, Y).\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Example: Computing the slope coefficient and intercept term**\n",
    "\n",
    "Compute the slope coefficient and intercept term using the following information:\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>Cov(S&amp;P 500, ABC</td>\n",
    "    <td>0.000336</td>\n",
    "    <td>Mean return, S&amp;P 500</td>\n",
    "    <td>−2.70%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Var(S&amp;P 500)</td>\n",
    "    <td>0.000522</td>\n",
    "    <td>Mean return, ABC</td>\n",
    "    <td>−4.05%</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The slope coefficient is calculated as $\\hat{b}_{1} = \\frac{0.000336}{0.000522} = 0.64$.\n",
    "\n",
    "The intercept term is calculated as follows:\n",
    "\n",
    "$\\hat{b}_{0}=\\overline{ABC}−\\hat{b}_{1}\\overline{SP500}=−4.05\\% −0.64 (−2.70\\%) = −2.3\\%$\n",
    "<br>\n",
    "</br>\n",
    "The estimated regression line that minimizes the SSE in our ABC stock return example is shown in  Estimated Regression Equation for ABC vs. S&P 500 Excess Returns.\n",
    "\n",
    "<br>\n",
    "This regression line has an intercept of $–2.3\\%$ and a slope of $0.64$. The model predicts that if the S&P 500 excess return is $–7.8\\%$ (May 20X4 value), then the ABC excess return would be $–2.3\\% + (0.64)(–7.8\\%) = –7.3\\%$. The residual (error) for the May 20X4 ABC prediction is $8.4\\%$—the difference between the actual ABC excess return of $1.1\\%$ and the predicted return of $–7.3\\%$.\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d09d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "covAB= 0.000336\n",
    "ABC_Var = 0.000522\n",
    "SP500_Mu = -2.70\n",
    "ABC_Mu = -4.05\n",
    "## Define the Slope intercept\n",
    "bhat_1 = covAB / ABC_Var\n",
    "bhat_0 = ABC_Mu - (bhat_1*SP500_Mu)\n",
    "\n",
    "#Excess returns\n",
    "excessSP = bhat_0 + bhat_1 * -7.8\n",
    "\n",
    "#Actual ABC returns\n",
    "actABC = 1.1\n",
    "sse = actABC - excessSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7439d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope Coeffiecient b^1   =   0.64\n",
      "Intercept b^0            =  -2.3\n",
      "Excess returns of SP500  =  -7.3\n",
      "Actual returns of ABC    =   1.1\n",
      "SSE Error ABC prediction =   8.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Slope Coeffiecient b^1   =  \", round(bhat_1, 2))\n",
    "print(\"Intercept b^0            = \", round(bhat_0, 1))\n",
    "print(\"Excess returns of SP500  = \", round(excessSP, 1))\n",
    "print(\"Actual returns of ABC    =  \", round(actABC, 1))\n",
    "print(\"SSE Error ABC prediction =  \", round(sse, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e268d8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/PachaTech/CFA-Level-1/blob/main/10_1%20graph.jpeg?raw=true\">\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d51fff",
   "metadata": {},
   "source": [
    "A Simple linear regression explains the variation in a dependent variable $Y$ in terms of the variation in a single independent variable $X$\n",
    "\n",
    "#### Assumptions of a Simple Linear Regression\n",
    "\n",
    "1. The relationship between $X$ independent and $Y$ dependent does (must) exist. \n",
    "2. Error terms are normally distrubuted. Their $\\mu=0$\n",
    "3. The variance $\\sigma$ of the error term is constant *(Homoskedastic)*.\n",
    "4. Error terms are independently distributed and uncorrelated with each other, *(serial or autocorrelation)*.  \n",
    "5. Error terms are not random.\n",
    "\n",
    "<hr></hr>\n",
    "\n",
    "#### Results can be an issue for Standard Error terms or to Hypothesis testing.\n",
    "* HOMOSKEDACITY - refers to the case where all prediction errors all have the same constant variance.  $\\sigma = c$\n",
    "<br>\n",
    "\n",
    "* HETEROSKEDACITY - refers to the variance of the error terms $\\epsilon$ not being constant.    $\\sigma \\neq c$\n",
    "<br>\n",
    "\n",
    "* Conditional HETEROSKEDACITY -  where the variance of the error terms is related to the independent variable.  \n",
    "*i.e. if the independent variable is getting bigger and bigger or the variance is increasing and getting bigger.  Maybe, the independent variable is getting smaller and the variance is getting smaller too.*\n",
    "<br>\n",
    "\n",
    "#### NOTES\n",
    "* The model **does not** assume that the dependent variable is uncorrelated with the residuals. \n",
    "* The model **does assume** that the independent variable is uncorrelated with the residuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b3d61",
   "metadata": {},
   "source": [
    "# Module 10.2: Analysis of Variance (ANOVA) and Goodness of Fit\n",
    "\n",
    "<hr>\n",
    "\n",
    "### LOS 10.c: Calculate and interpret measures of fit and formulate and evaluate tests of fit and of regression coefficients in a simple linear regression.\n",
    "\n",
    "\n",
    "### LOS 10.d: Describe the use of analysis of variance (ANOVA) in regression analysis, interpret ANOVA results, and calculate and interpret the standard error of estimate in a simple linear regression.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Analysis of variance (ANOVA)** is a statistical procedure for analyzing the total variability of the dependent variable. Let's define some terms before we move on to ANOVA tables:\n",
    "\n",
    "* The **total sum of squares (SST)** measures the total variation in the dependent variable. SST is equal to the sum of the squared differences between the actual $Y$-values and the mean of $Y$:\n",
    "\n",
    "$\\qquad\\large\\text{SST}=\\displaystyle\\sum_{i=1}^n(Y_i−\\overline{Y})^2$\n",
    "\n",
    "* The **sum of squares regression (SSR)** measures the variation in the dependent variable that is explained by the independent variable. SSR is the sum of the squared distances between the predicted $Y$-values and the mean of $Y$:\n",
    "\n",
    "$\\qquad\\large\\text{SSR}=\\displaystyle\\sum_{i=1}^n(\\hat{Y}−\\overline{Y})^2$\n",
    "\n",
    "* The **mean square regression (MSR)** is the SSR divided by the number of independent variables. A simple linear regression has only one independent variable, so in this case, MSR = SSR.\n",
    "\n",
    "#### Professor's Note\n",
    "\n",
    "Multiple regression (i.e., with more than one independent variable) is addressed in the Level II CFA curriculum.\n",
    "\n",
    "* The **sum of squared errors (SSE)** measures the unexplained variation in the dependent variable. It's also known as the sum of squared residuals or the residual sum of squares. SSE is the sum of the squared vertical distances between the actual $Y$-values and the predicted $Y$-values on the regression line:\n",
    "<br>\n",
    "\n",
    "$\\qquad\\large\\text{SSR}=\\displaystyle\\sum_{i=1}^n(Y_i−\\hat{Y})^2$\n",
    "\n",
    "</br>\n",
    "\n",
    "* The **mean squared error (MSE)** is the SSE divided by the degrees of freedom, which is $n – 1$ minus the number of independent variables. A simple linear regression has only one independent variable, so in this case, degrees of freedom are $n – 2$.\n",
    "\n",
    "<br>\n",
    "\n",
    "You probably will not be surprised to learn the following:\n",
    "<br>\n",
    "\n",
    "$\\qquad\\text{total variation = explained variation + unexplained variation}$\n",
    "\n",
    "<br>\n",
    "or:\n",
    "\n",
    "<br>\n",
    "$\\qquad\\text{SST = SSR + SSE}$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Components of Total Variation** illustrates how the total variation in the dependent variable (SST) is composed of SSR and SSE.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/PachaTech/CFA-Level-1/blob/main/10_2%20chart.jpeg?raw=true\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c15ed",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "The output of the ANOVA procedure is an ANOVA table, which is a summary of the variation in the dependent variable. ANOVA tables are included in the regression output of many statistical software packages. You can think of the ANOVA table as the source of the data for the computation of many of the regression concepts discussed in this reading. A generic ANOVA table for a simple linear regression (one independent variable) is presented in  **ANOVA Table for a Simple Linear Regression**.\n",
    "\n",
    "<img src=\"https://github.com/PachaTech/CFA-Level-1/blob/main/10_2.jpeg?raw=true\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a9cea",
   "metadata": {},
   "source": [
    "#### Standard Error of Estimate (SEE)\n",
    "\n",
    "The SEE for a regression is the standard deviation of its residuals. The lower the SEE, the better the model fit:\n",
    "\n",
    "$\\qquad\\text{SEE} = \\sqrt{MSE}$\n",
    "\n",
    "#### Coefficient of Determination (R2)\n",
    "\n",
    "The coefficient of determination (R2) is defined as the percentage of the total variation in the dependent variable explained by the independent variable. For example, an R2 of 0.63 indicates that the variation of the independent variable explains 63% of the variation in the dependent variable:\n",
    "\n",
    "$\\qquad\\large{R^2 = \\frac{\\text{SSR}}{\\text{SST}}}$\n",
    "\n",
    "#### Professor's Note\n",
    "\n",
    "For simple linear regression (i.e., with one independent variable), the coefficient of determination, $R^2$, may be computed by simply squaring the correlation coefficient, $r$. In other words, $R^2 = r^2$ for a regression with one independent variable.\n",
    "\n",
    "**Example:** Using the ANOVA table\n",
    "\n",
    "Given the following ANOVA table based on 36 observations, calculate the $R^2$ and the standard error of estimate (SEE).\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "**Completed ANOVA table for ABC regression**\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Source of Variation</th>\n",
    "    <th>Degrees of Freedom</th>\n",
    "    <th>Sum of Squares</th>\n",
    "    <th>Mean Sum of Squares</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>Regression (explained)</td>\n",
    "    <td>1</td>\n",
    "    <td>0.0076</td>\n",
    "    <td>0.0076</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Error (unexplained)</td>\n",
    "    <td>34</td>\n",
    "    <td>0.0406</td>\n",
    "    <td>0.0012</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Total</td>\n",
    "    <td>35</td>\n",
    "    <td>0.0482</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Answer**\n",
    "\n",
    "$\\quad\\large R^2=\\frac{\\text{explained variation (SSR)}}{\\text{total variation (SST)}} = \\frac{0.0076}{0.0482}=0.158$ or 15.8% \n",
    "\n",
    "<br>\n",
    "\n",
    "$\\qquad\\text{SEE}=\\sqrt{MSE}=\\sqrt{0.0012}=0.035$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75add94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input the variables\n",
    "SSR = 0.0076\n",
    "SST = 0.0482\n",
    "\n",
    "## Solve for coefficient of determination (R^2)\n",
    "MSE = (SSR / SST)\n",
    "\n",
    "## Calculate SEE\n",
    "SEE = math.sqrt(0.0012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7470ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variation (SSR)          =   0.008\n",
      "Total Variation     (SST)          =   0.048\n",
      "coefficient of determination (R^2) =   0.158\n",
      "coefficient of determination (R^2) =   15.8\n",
      "%\n",
      "Standard Error of Estimate (SEE)   =   0.035\n"
     ]
    }
   ],
   "source": [
    "## Print variables\n",
    "print(\"Explained Variation (SSR)          =  \", round(SSR, 3))\n",
    "print(\"Total Variation     (SST)          =  \", round(SST, 3))\n",
    "print(\"coefficient of determination (R^2) =  \", round(MSE, 3))\n",
    "print(\"coefficient of determination (R^2) =  \", round(MSE*100,1)),print(\"%\")\n",
    "print(\"Standard Error of Estimate (SEE)   =  \", round(SEE, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d86e2f",
   "metadata": {},
   "source": [
    "#### The F-Statistic\n",
    "\n",
    "An *F*-test assesses how well a set of independent variables, as a group, explains the variation in the dependent variable.\n",
    "\n",
    "The *F*-statistic is calculated as follows:\n",
    "\n",
    "<br>\n",
    "$\\quad\\large\\text{F}=\\frac{\\text{MSR}}{\\text{MSE}}=\\frac{\\text{SSR}\\div K}{\\text{SSE}\\div(n-k-1)}$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\text{MSR} =$ mean regression sum of squares\n",
    "\n",
    "$\\text{MSE} =$ mean squared error\n",
    "\n",
    "**Important**: This is always a one-tailed test\n",
    "\n",
    "<br>\n",
    "For simple linear regression, there is only one independent variable, so the $F$-test is equivalent to a $t$-test of the statistical significance of the slope coefficient:\n",
    "\n",
    "$\\qquad H_0: b_1 = 0$   versus   $H_a: b_1 \\neq 0$\n",
    "\n",
    "To determine whether $b_1$ is statistically significant using the $F$-test, the calculated $F$-statistic is compared with the critical $F$-value, $F_c$, at the appropriate level of significance. The degrees of freedom for the numerator and denominator with one independent variable are as follows:\n",
    "\n",
    "$\\qquad df_{\\text{numerator}} = k = 1$\n",
    "\n",
    "$\\qquad df_{\\text{denominator}} = n − k − 1 = n − 2$\n",
    "\n",
    "where:\n",
    "\n",
    "$n =$ number of observations\n",
    "\n",
    "The decision rule for the $F$-test is to reject $H_0$ if $F > F_c$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Rejecting the null hypothesis that the value of the slope coefficient equals zero at a stated level of significance indicates that the independent variable and the dependent variable have a significant linear relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
